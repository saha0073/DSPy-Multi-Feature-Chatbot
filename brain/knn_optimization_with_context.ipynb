{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5408402d-4d27-4ec1-8b8b-3435c4db9ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subho\\anaconda3\\envs\\whisper2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models import ChatMessage, ChatHistory\n",
    "import dspy\n",
    "from lms.together import Together\n",
    "\n",
    "from modules.chatter import ChatterModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5820760a-c1a5-43ff-961e-8f6293ff1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = Together(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=1000,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.2,\n",
    "    stop=[\"<|eot_id|>\", \"<|eom_id|>\", \"\\n\\n---\\n\\n\", \"\\n\\n---\", \"---\", \"\\n---\"],\n",
    "    # stop=[\"\\n\", \"\\n\\n\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd7dc5f-9093-4aff-9570-4f2fb32145a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c16553-759e-4d34-a22b-9937096b62f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 8\n",
      "Dev examples: 2\n",
      "Training examples: 8\n",
      "Dev examples: 2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from modules.chatter import (\n",
    "    ChatMessage, \n",
    "    ChatHistory, \n",
    "    MessageContext,\n",
    "    format_chat_history,\n",
    "    format_context\n",
    ")\n",
    "import dspy\n",
    "\n",
    "def load_and_split_data(file_path='../training_data/conversation_with_context.json'):\n",
    "    # Load the dataset\n",
    "    with open(file_path, 'r') as f:\n",
    "        conversations = json.load(f)\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "    random.shuffle(conversations)\n",
    "\n",
    "    # Split into train (80%) and dev (20%) sets\n",
    "    split_idx = int(len(conversations) * 0.8)\n",
    "    train_data = conversations[:split_idx]\n",
    "    dev_data = conversations[split_idx:]\n",
    "\n",
    "    def create_example(conv):\n",
    "        # Create MessageContext objects\n",
    "        messages = []\n",
    "        for msg in conv['chat_history']['messages']:\n",
    "            context = MessageContext(**msg['context'])\n",
    "            messages.append(ChatMessage(\n",
    "                from_creator=msg['from_creator'],\n",
    "                content=msg['content'],\n",
    "                context=context\n",
    "            ))\n",
    "        \n",
    "        # Create ChatHistory object\n",
    "        chat_history = ChatHistory(messages=messages)\n",
    "        last_context = messages[-1].context\n",
    "        \n",
    "        # Convert to strings for DSPy\n",
    "        chat_str = format_chat_history(chat_history)\n",
    "        context_str = format_context(last_context)\n",
    "        \n",
    "        return dspy.Example({\n",
    "            'chat_history': chat_str,\n",
    "            'context': context_str,\n",
    "            'output': conv['output']\n",
    "        }).with_inputs('chat_history', 'context')\n",
    "\n",
    "    trainset = [create_example(conv) for conv in train_data]\n",
    "    devset = [create_example(conv) for conv in dev_data]\n",
    "\n",
    "    print(f\"Training examples: {len(trainset)}\")\n",
    "    print(f\"Dev examples: {len(devset)}\")\n",
    "    \n",
    "    return trainset, devset\n",
    "    \n",
    "trainset, devset=load_and_split_data()\n",
    "\n",
    "print(f\"Training examples: {len(trainset)}\")\n",
    "print(f\"Dev examples: {len(devset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142f20cd-a909-4883-990e-714e478bb905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example Structure:\n",
      "Chat History:\n",
      "Fan [Time: afternoon, Message #1]: I feel like I'm always 'rediscovering' myself. Is that normal, or am I just indecisive?\n",
      "Creator [Time: afternoon, Message #2]: Rediscovery is a sign of growth. We're constantly evolving, and it's healthy to question who you are.\n",
      "Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "\n",
      "Expected Output:\n",
      "That's the beauty of self-discovery. Embrace the chaosâ€”it means you're alive and curious.\n"
     ]
    }
   ],
   "source": [
    "# Example from trainset\n",
    "example = trainset[0]\n",
    "print(\"Training Example Structure:\")\n",
    "print(\"Chat History:\")\n",
    "print(example.chat_history)  # Now this is a formatted string\n",
    "print(\"\\nContext:\")\n",
    "print(example.context)\n",
    "print(\"\\nExpected Output:\")\n",
    "print(example.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809251b5-bdf2-4ba3-a402-2ed89c439b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with k=2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Input conversation:\n",
      "Fan [Time: afternoon, Message #1]: I feel like I'm always 'rediscovering' myself. Is that normal, or am I just indecisive?\n",
      "Creator [Time: afternoon, Message #2]: Rediscovery is a sign of growth. We're constantly evolving, and it's healthy to question who you are.\n",
      "Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "\n",
      "Model output: This journey of discovery will help shape your values and passions over time. Enjoy the process!\n",
      "\n",
      "Nearest 2 neighbors used:\n",
      "\n",
      "Neighbor 1:\n",
      "Chat History:\n",
      "Fan [Time: afternoon, Message #1]: I feel like I'm always 'rediscovering' myself. Is that normal, or am I just indecisive?\n",
      "Creator [Time: afternoon, Message #2]: Rediscovery is a sign of growth. We're constantly evolving, and it's healthy to question who you are.\n",
      "Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: That's the beauty of self-discovery. Embrace the chaosâ€”it means you're alive and curious.\n",
      "\n",
      "Neighbor 2:\n",
      "Chat History:\n",
      "Fan [Time: afternoon, Message #1]: Do you ever feel like the idea of 'self-improvement' is just another way to make people feel inadequate?\n",
      "Creator [Time: afternoon, Message #2]: That's a deep question. True self-improvement shouldn't make you feel lacking. It's about becoming more yourself, not something else.\n",
      "Fan [Time: afternoon, Message #3]: I like that. Like, I can just be me but maybe a little less chaotic?\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: Exactly! Improvement isn't about fixing, just embracing yourself with more awareness and acceptance.\n",
      "\n",
      "Testing with k=3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "Input conversation:\n",
      "Fan [Time: afternoon, Message #1]: I feel like I'm always 'rediscovering' myself. Is that normal, or am I just indecisive?\n",
      "Creator [Time: afternoon, Message #2]: Rediscovery is a sign of growth. We're constantly evolving, and it's healthy to question who you are.\n",
      "Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "\n",
      "Model output: Remember, every step forward might mean leaving some things behind, but what you gain from each journey inward will enrich your path ahead.\n",
      "\n",
      "Nearest 3 neighbors used:\n",
      "\n",
      "Neighbor 1:\n",
      "Chat History:\n",
      "Fan [Time: afternoon, Message #1]: I feel like I'm always 'rediscovering' myself. Is that normal, or am I just indecisive?\n",
      "Creator [Time: afternoon, Message #2]: Rediscovery is a sign of growth. We're constantly evolving, and it's healthy to question who you are.\n",
      "Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: That's the beauty of self-discovery. Embrace the chaosâ€”it means you're alive and curious.\n",
      "\n",
      "Neighbor 2:\n",
      "Chat History:\n",
      "Fan [Time: afternoon, Message #1]: Do you ever feel like the idea of 'self-improvement' is just another way to make people feel inadequate?\n",
      "Creator [Time: afternoon, Message #2]: That's a deep question. True self-improvement shouldn't make you feel lacking. It's about becoming more yourself, not something else.\n",
      "Fan [Time: afternoon, Message #3]: I like that. Like, I can just be me but maybe a little less chaotic?\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: Exactly! Improvement isn't about fixing, just embracing yourself with more awareness and acceptance.\n",
      "\n",
      "Neighbor 3:\n",
      "Chat History:\n",
      "Fan [Time: evening, Message #1]: I sometimes feel like I'm an 'old soul' in a world that's moving too fast. Is that weird?\n",
      "Creator [Time: evening, Message #2]: Not at all. Some people connect deeply with past eras, and that's perfectly valid. It's about finding your own rhythm.\n",
      "Fan [Time: evening, Message #3]: That's really reassuring. Sometimes I just want to escape into another time.\n",
      "Context:\n",
      "Current context: Time of day: evening, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: That's understandable. Just remember that you can bring elements of those eras into your life now.\n",
      "\n",
      "Testing with k=4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "\n",
      "Input conversation:\n",
      "Fan [Time: afternoon, Message #1]: I feel like I'm always 'rediscovering' myself. Is that normal, or am I just indecisive?\n",
      "Creator [Time: afternoon, Message #2]: Rediscovery is a sign of growth. We're constantly evolving, and it's healthy to question who you are.\n",
      "Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "\n",
      "Model output: That's the beauty of self-discovery. Embrace the chaos—it means you're alive and curious.\n",
      "\n",
      "Nearest 4 neighbors used:\n",
      "\n",
      "Neighbor 1:\n",
      "Chat History:\n",
      "Fan [Time: afternoon, Message #1]: I feel like I'm always 'rediscovering' myself. Is that normal, or am I just indecisive?\n",
      "Creator [Time: afternoon, Message #2]: Rediscovery is a sign of growth. We're constantly evolving, and it's healthy to question who you are.\n",
      "Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: That's the beauty of self-discovery. Embrace the chaosâ€”it means you're alive and curious.\n",
      "\n",
      "Neighbor 2:\n",
      "Chat History:\n",
      "Fan [Time: afternoon, Message #1]: Do you ever feel like the idea of 'self-improvement' is just another way to make people feel inadequate?\n",
      "Creator [Time: afternoon, Message #2]: That's a deep question. True self-improvement shouldn't make you feel lacking. It's about becoming more yourself, not something else.\n",
      "Fan [Time: afternoon, Message #3]: I like that. Like, I can just be me but maybe a little less chaotic?\n",
      "Context:\n",
      "Current context: Time of day: afternoon, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: Exactly! Improvement isn't about fixing, just embracing yourself with more awareness and acceptance.\n",
      "\n",
      "Neighbor 3:\n",
      "Chat History:\n",
      "Fan [Time: evening, Message #1]: I sometimes feel like I'm an 'old soul' in a world that's moving too fast. Is that weird?\n",
      "Creator [Time: evening, Message #2]: Not at all. Some people connect deeply with past eras, and that's perfectly valid. It's about finding your own rhythm.\n",
      "Fan [Time: evening, Message #3]: That's really reassuring. Sometimes I just want to escape into another time.\n",
      "Context:\n",
      "Current context: Time of day: evening, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: That's understandable. Just remember that you can bring elements of those eras into your life now.\n",
      "\n",
      "Neighbor 4:\n",
      "Chat History:\n",
      "Fan [Time: evening, Message #1]: How would you balance being an introvert with the need for connection? I feel like I live in a world of my own...\n",
      "Creator [Time: evening, Message #2]: The key is finding people who appreciate your world rather than requiring you to leave it. True connection can be simple and quiet.\n",
      "Fan [Time: evening, Message #3]: That's really comforting. I always thought connection had to be extroverted.\n",
      "Context:\n",
      "Current context: Time of day: evening, Message #3, Minutes since start: 10, Minutes since last: 5\n",
      "Response: Not at all. It's about quality, not quantity. Authentic connection doesn't demand you to be someone you're not.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import KNNFewShot\n",
    "from modules.chatter import ChatterModule\n",
    "\n",
    "def metric(example, prediction, trace=None):\n",
    "    # For string comparison\n",
    "    pred_output = prediction if isinstance(prediction, str) else prediction.output\n",
    "    expected_output = example.output if hasattr(example, 'output') else example\n",
    "    return pred_output == expected_output\n",
    "\n",
    "def test_knn(k_value, trainset):\n",
    "    print(f\"\\nTesting with k={k_value}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    bootstrap_args = {\n",
    "        'metric': metric,\n",
    "        'max_bootstrapped_demos': 2,\n",
    "        'max_labeled_demos': 4,\n",
    "        'max_rounds': 1,\n",
    "        'max_errors': 5\n",
    "    }\n",
    "\n",
    "    knn_teleprompter = KNNFewShot(\n",
    "        k=k_value,\n",
    "        trainset=trainset,\n",
    "        **bootstrap_args\n",
    "    )\n",
    "\n",
    "    chatter = ChatterModule(examples=None)\n",
    "    compiled_knn = knn_teleprompter.compile(\n",
    "        student=chatter,\n",
    "        trainset=trainset\n",
    "    )\n",
    "\n",
    "    # Test with sample input\n",
    "    test_history = trainset[0].chat_history\n",
    "    test_context = trainset[0].context\n",
    "    \n",
    "    try:\n",
    "        result = compiled_knn(chat_history=test_history, context=test_context)\n",
    "        response = result if isinstance(result, str) else result.output\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        response = \"Error generating response\"\n",
    "    \n",
    "    try:\n",
    "        # Get and print neighbors\n",
    "        neighbors = knn_teleprompter.KNN(chat_history=test_history, context=test_context)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting neighbors: {e}\")\n",
    "        neighbors = []\n",
    "    \n",
    "    print(f\"\\nInput conversation:\")\n",
    "    print(test_history)\n",
    "    \n",
    "    print(f\"\\nContext:\")\n",
    "    print(test_context)\n",
    "    \n",
    "    print(f\"\\nModel output: {response}\")\n",
    "    \n",
    "    if neighbors:\n",
    "        print(f\"\\nNearest {k_value} neighbors used:\")\n",
    "        for i, n in enumerate(neighbors):\n",
    "            print(f\"\\nNeighbor {i+1}:\")\n",
    "            print(\"Chat History:\")\n",
    "            print(n.chat_history)\n",
    "            print(\"Context:\")\n",
    "            print(n.context)\n",
    "            print(f\"Response: {n.output if hasattr(n, 'output') else 'No output available'}\")\n",
    "\n",
    "# Test with different k values\n",
    "for k in [2, 3, 4]:\n",
    "    test_knn(k, trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0071aee9-d5f3-4e26-a40d-f64209fcaff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing k=2 with 5 samples\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Sample 1:\n",
      "Input: Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "Expected: That's the beauty of self-discovery. Embrace the chaosâ€”it means you're alive and curious.\n",
      "Generated: You're on a journey of continuous discovery, which takes courage and openness. Keep exploring!\n",
      "ROUGE-L: 0.188\n",
      "Semantic Similarity: 0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Sample 5:\n",
      "Input: Fan [Time: evening, Message #3]: I love that idea. Maybe right now, I'm in my 'mystical science' chapter.\n",
      "Expected: Exactly! Allow yourself to dive deeply into each chapter. Your interests are like seasonsâ€”they come and go with purpose.\n",
      "Generated: Exactly! Allow yourself to dive deeply into each chapter. Your interests are like seasons—they come and go with purpose.\n",
      "ROUGE-L: 1.000\n",
      "Semantic Similarity: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Sample 2:\n",
      "Input: Fan [Time: morning, Message #3]: Wow, I never thought of it that way. Like, each key is a choice or a mystery.\n",
      "Expected: Exactly! Sometimes the things we keep have deeper symbolism, even if we don't realize it consciously.\n",
      "Generated: Do any particular keys stand out to you for some reason, or hold special significance?\n",
      "ROUGE-L: 0.000\n",
      "Semantic Similarity: 0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Sample 7:\n",
      "Input: Fan [Time: morning, Message #3]: I'll try focusing on my small joysâ€”like vintage records and herbal teas.\n",
      "Expected: Perfect. Those are your anchors. In a chaotic world, even small rituals can be deeply meaningful.\n",
      "Generated: That sounds lovely! Embracing what brings you joy can indeed provide a sense of grounding and connection. Exploring how these simple pleasures might also inspire new perspectives or creative outlets could further enrich your experience.\n",
      "ROUGE-L: 0.039\n",
      "Semantic Similarity: 0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Sample 4:\n",
      "Input: Fan [Time: evening, Message #3]: That's really reassuring. Sometimes I just want to escape into another time.\n",
      "Expected: That's understandable. Just remember that you can bring elements of those eras into your life now.\n",
      "Generated: You might explore hobbies or interests inspired by earlier times—reading classic literature, learning historical dances, or practicing traditional crafts—that allow you to express these aspects of yourself within today’s world.\n",
      "ROUGE-L: 0.120\n",
      "Semantic Similarity: 0.378\n",
      "\n",
      "Testing k=3 with 5 samples\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "Sample 1:\n",
      "Input: Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "Expected: That's the beauty of self-discovery. Embrace the chaosâ€”it means you're alive and curious.\n",
      "Generated: That's the beauty of self-discovery. Embrace the chaos—it means you're alive and curious.\n",
      "ROUGE-L: 1.000\n",
      "Semantic Similarity: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "Sample 5:\n",
      "Input: Fan [Time: evening, Message #3]: I love that idea. Maybe right now, I'm in my 'mystical science' chapter.\n",
      "Expected: Exactly! Allow yourself to dive deeply into each chapter. Your interests are like seasonsâ€”they come and go with purpose.\n",
      "Generated: Dive deep into your mystical science chapter; every exploration enriches your story, and new chapters await when the time comes.\n",
      "ROUGE-L: 0.250\n",
      "Semantic Similarity: 0.540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "Sample 2:\n",
      "Input: Fan [Time: morning, Message #3]: Wow, I never thought of it that way. Like, each key is a choice or a mystery.\n",
      "Expected: Exactly! Sometimes the things we keep have deeper symbolism, even if we don't realize it consciously.\n",
      "Generated: Exactly! Sometimes the things we keep have deeper symbolism, even if we don't realize it consciously.\n",
      "ROUGE-L: 1.000\n",
      "Semantic Similarity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 3/3 [00:19<00:00,  6.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "Sample 7:\n",
      "Input: Fan [Time: morning, Message #3]: I'll try focusing on my small joysâ€”like vintage records and herbal teas.\n",
      "Expected: Perfect. Those are your anchors. In a chaotic world, even small rituals can be deeply meaningful.\n",
      "Generated: Perfect. Those are your anchors. In a chaotic world, even small rituals can be deeply meaningful.\n",
      "ROUGE-L: 1.000\n",
      "Semantic Similarity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "Sample 4:\n",
      "Input: Fan [Time: evening, Message #3]: That's really reassuring. Sometimes I just want to escape into another time.\n",
      "Expected: That's understandable. Just remember that you can bring elements of those eras into your life now.\n",
      "Generated: \"It's natural to yearn for different times, especially when feeling overwhelmed. Instead of escaping, consider how these interests can enrich your daily life—whether through hobbies, reading, or simply appreciating the timeless qualities they offer.\"\n",
      "ROUGE-L: 0.151\n",
      "Semantic Similarity: 0.418\n",
      "\n",
      "Testing k=4 with 5 samples\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 4/4 [00:20<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "\n",
      "Sample 1:\n",
      "Input: Fan [Time: afternoon, Message #3]: It feels chaotic, but I also feel like I'm learning so much about myself.\n",
      "Expected: That's the beauty of self-discovery. Embrace the chaosâ€”it means you're alive and curious.\n",
      "Generated: That's the beauty of self-discovery. You get to peel back layers and find out what truly resonates within you.\n",
      "ROUGE-L: 0.474\n",
      "Semantic Similarity: 0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 4/4 [00:28<00:00,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "\n",
      "Sample 5:\n",
      "Input: Fan [Time: evening, Message #3]: I love that idea. Maybe right now, I'm in my 'mystical science' chapter.\n",
      "Expected: Exactly! Allow yourself to dive deeply into each chapter. Your interests are like seasonsâ€”they come and go with purpose.\n",
      "Generated: Exactly! Allow yourself to dive deeply into each chapter. Your interests are like seasons—they come and go with purpose.\n",
      "ROUGE-L: 1.000\n",
      "Semantic Similarity: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "\n",
      "Sample 2:\n",
      "Input: Fan [Time: morning, Message #3]: Wow, I never thought of it that way. Like, each key is a choice or a mystery.\n",
      "Expected: Exactly! Sometimes the things we keep have deeper symbolism, even if we don't realize it consciously.\n",
      "Generated: \"It seems like your collection holds not only aesthetic appeal but also emotional depth. Have you ever considered what draws you specifically to one piece over another?\"\n",
      "ROUGE-L: 0.045\n",
      "Semantic Similarity: 0.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "\n",
      "Sample 7:\n",
      "Input: Fan [Time: morning, Message #3]: I'll try focusing on my small joysâ€”like vintage records and herbal teas.\n",
      "Expected: Perfect. Those are your anchors. In a chaotic world, even small rituals can be deeply meaningful.\n",
      "Generated: Perfect. Those are your anchors. In a chaotic world, even small rituals can be deeply meaningful.\n",
      "ROUGE-L: 1.000\n",
      "Semantic Similarity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "\n",
      "Sample 4:\n",
      "Input: Fan [Time: evening, Message #3]: That's really reassuring. Sometimes I just want to escape into another time.\n",
      "Expected: That's understandable. Just remember that you can bring elements of those eras into your life now.\n",
      "Generated: You might enjoy exploring historical reenactments or themed events as a way to step into other times without leaving yours behind.\n",
      "ROUGE-L: 0.158\n",
      "Semantic Similarity: 0.472\n",
      "\n",
      "Overall Results:\n",
      "--------------------------------------------------\n",
      "\n",
      "k=2:\n",
      "Average ROUGE-L: 0.269 (±0.371)\n",
      "Average Semantic Similarity: 0.502 (±0.263)\n",
      "\n",
      "k=3:\n",
      "Average ROUGE-L: 0.680 (±0.393)\n",
      "Average Semantic Similarity: 0.783 (±0.252)\n",
      "\n",
      "k=4:\n",
      "Average ROUGE-L: 0.535 (±0.404)\n",
      "Average Semantic Similarity: 0.661 (±0.279)\n"
     ]
    }
   ],
   "source": [
    "# First cell - imports\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "from dspy.teleprompt import KNNFewShot\n",
    "from modules.chatter import ChatterModule\n",
    "\n",
    "# Second cell - evaluator class\n",
    "class ResponseEvaluator:\n",
    "    def __init__(self):\n",
    "        self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "    def calculate_metrics(self, prediction, reference):\n",
    "        # ROUGE scores\n",
    "        try:\n",
    "            scores = self.scorer.score(reference, prediction)\n",
    "            rouge_l = scores['rougeL'].fmeasure\n",
    "        except:\n",
    "            rouge_l = 0\n",
    "            \n",
    "        # Semantic similarity using SBERT\n",
    "        pred_emb = self.encoder.encode([prediction])[0]\n",
    "        ref_emb = self.encoder.encode([reference])[0]\n",
    "        semantic_sim = cosine_similarity([pred_emb], [ref_emb])[0][0]\n",
    "        \n",
    "        return {\n",
    "            'rouge_l': rouge_l,\n",
    "            'semantic_sim': semantic_sim\n",
    "        }\n",
    "\n",
    "# Third cell - test function\n",
    "def test_knn(k_value, trainset, test_example, verbose=True):\n",
    "    bootstrap_args = {\n",
    "        'metric': metric,\n",
    "        'max_bootstrapped_demos': 2,\n",
    "        'max_labeled_demos': 4,\n",
    "        'max_rounds': 1,\n",
    "        'max_errors': 5\n",
    "    }\n",
    "\n",
    "    knn_teleprompter = KNNFewShot(\n",
    "        k=k_value,\n",
    "        trainset=trainset,\n",
    "        **bootstrap_args\n",
    "    )\n",
    "\n",
    "    chatter = ChatterModule(examples=None)\n",
    "    compiled_knn = knn_teleprompter.compile(\n",
    "        student=chatter,\n",
    "        trainset=trainset\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = compiled_knn(\n",
    "            chat_history=test_example.chat_history,\n",
    "            context=test_example.context\n",
    "        )\n",
    "        response = result if isinstance(result, str) else result.output\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "        response = \"Error generating response\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Fourth cell - evaluation function\n",
    "def evaluate_k_values(trainset, k_values=[2, 3, 4], num_samples=5):  # Reduced samples for faster testing\n",
    "    evaluator = ResponseEvaluator()\n",
    "    results = {k: {'rouge': [], 'semantic': []} for k in k_values}\n",
    "    \n",
    "    # Sample conversations to test\n",
    "    test_indices = random.sample(range(len(trainset)), min(num_samples, len(trainset)))\n",
    "    \n",
    "    for k in k_values:\n",
    "        print(f\"\\nTesting k={k} with {num_samples} samples\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for idx in test_indices:\n",
    "            test_example = trainset[idx]\n",
    "            \n",
    "            # Get model response for this k value\n",
    "            response = test_knn(k, trainset, test_example, verbose=False)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = evaluator.calculate_metrics(response, test_example.output)\n",
    "            \n",
    "            results[k]['rouge'].append(metrics['rouge_l'])\n",
    "            results[k]['semantic'].append(metrics['semantic_sim'])\n",
    "            \n",
    "            print(f\"\\nSample {idx + 1}:\")\n",
    "            messages = test_example.chat_history.split('\\n')\n",
    "            print(f\"Input: {messages[-1]}\")  # Last message\n",
    "            print(f\"Expected: {test_example.output}\")\n",
    "            print(f\"Generated: {response}\")\n",
    "            print(f\"ROUGE-L: {metrics['rouge_l']:.3f}\")\n",
    "            print(f\"Semantic Similarity: {metrics['semantic_sim']:.3f}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    print(\"\\nOverall Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    for k in k_values:\n",
    "        avg_rouge = np.mean(results[k]['rouge'])\n",
    "        avg_semantic = np.mean(results[k]['semantic'])\n",
    "        std_rouge = np.std(results[k]['rouge'])\n",
    "        std_semantic = np.std(results[k]['semantic'])\n",
    "        \n",
    "        print(f\"\\nk={k}:\")\n",
    "        print(f\"Average ROUGE-L: {avg_rouge:.3f} (±{std_rouge:.3f})\")\n",
    "        print(f\"Average Semantic Similarity: {avg_semantic:.3f} (±{std_semantic:.3f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Fifth cell - run evaluation\n",
    "# Make sure trainset is already loaded\n",
    "results = evaluate_k_values(trainset, k_values=[2, 3, 4], num_samples=5)  # Reduced samples for faster testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0472c22-4ca6-4e7d-9f22-1f2b21dcdee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to: saved_models/optimized_chatbot_with_context.json\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import KNNFewShot\n",
    "from modules.chatter import ChatterModule\n",
    "import os\n",
    "\n",
    "def metric(example, prediction, trace=None):\n",
    "    return example.output == prediction.output\n",
    "\n",
    "# Create the KNN teleprompter with optimal parameters\n",
    "bootstrap_args = {\n",
    "    'metric': metric,\n",
    "    'max_bootstrapped_demos': 2,\n",
    "    'max_labeled_demos': 4,\n",
    "    'max_rounds': 1,\n",
    "    'max_errors': 5\n",
    "}\n",
    "\n",
    "# Initialize KNN with k=3 (as per our evaluation)\n",
    "knn_teleprompter = KNNFewShot(\n",
    "    k=3,  # Using 3 nearest neighbors based on evaluation\n",
    "    trainset=trainset,\n",
    "    **bootstrap_args\n",
    ")\n",
    "\n",
    "# Create and compile\n",
    "chatter = ChatterModule(examples=None)\n",
    "compiled_knn = knn_teleprompter.compile(\n",
    "    student=chatter,\n",
    "    trainset=trainset\n",
    ")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Save the compiled model\n",
    "compiled_knn.save(\"saved_models/optimized_chatbot_with_context.json\")\n",
    "\n",
    "# Test function to verify the model works with context\n",
    "def test_model():\n",
    "    test_history = trainset[0].chat_history\n",
    "    test_context = trainset[0].messages[-1].context  # Get context from last message\n",
    "    \n",
    "    result = compiled_knn(\n",
    "        chat_history=test_history,\n",
    "        context=test_context\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTest Results:\")\n",
    "    print(\"Input conversation:\")\n",
    "    print(test_history)  # Using string representation\n",
    "    \n",
    "    print(f\"\\nContext:\")\n",
    "    print(f\"Time of day: {test_context.time_of_day}\")\n",
    "    print(f\"Message #: {test_context.message_number}\")\n",
    "    print(f\"Minutes since start: {test_context.minutes_since_start}\")\n",
    "    print(f\"Minutes since last: {test_context.minutes_since_last}\")\n",
    "    \n",
    "    print(f\"\\nModel output: {result.output}\")\n",
    "    \n",
    "    # Get and print neighbors with context\n",
    "    neighbors = knn_teleprompter.KNN(\n",
    "        chat_history=test_history,\n",
    "        context=test_context\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nNearest {len(neighbors)} neighbors used:\")\n",
    "    for i, n in enumerate(neighbors):\n",
    "        print(f\"\\nNeighbor {i+1}:\")\n",
    "        print(\"Chat History:\")\n",
    "        print(n.chat_history)\n",
    "        print(\"Context:\")\n",
    "        print(n.context)\n",
    "        print(f\"Response: {n.output}\")\n",
    "\n",
    "# Uncomment to test\n",
    "# test_model()\n",
    "\n",
    "print(f\"\\nModel saved to: saved_models/optimized_chatbot_with_context.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ac6fc9-5cfa-40ea-a957-a051da862bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat started! (Type 'quit' to exit)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creator: Hello! I'm an assistant designed to help answer questions and provide information on various topics. How can I assist you today?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creator: While I don't have a personal name like a human does, I'm here to be helpful and assist with any questions or tasks you might have! Think of me as your go-to resource whenever you need something clarified or looked up. Is there something specific you'd like assistance with tonight?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m message_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Get user input\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mChat ended. Goodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\whisper2\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\whisper2\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from modules.chatter import ChatterModule, ChatHistory, ChatMessage, MessageContext\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Load the optimized model\n",
    "chatter = ChatterModule(examples=None)\n",
    "chatter.load(path=\"saved_models/optimized_chatbot_with_context.json\")\n",
    "\n",
    "# Initialize chat history\n",
    "chat_history = ChatHistory(messages=[])\n",
    "start_time = time.time()\n",
    "last_message_time = start_time\n",
    "\n",
    "def get_context(message_number):\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Get time of day\n",
    "    hour = datetime.now().hour\n",
    "    if 5 <= hour < 12:\n",
    "        time_of_day = \"morning\"\n",
    "    elif 12 <= hour < 17:\n",
    "        time_of_day = \"afternoon\"\n",
    "    else:\n",
    "        time_of_day = \"evening\"\n",
    "    \n",
    "    # Calculate times\n",
    "    minutes_since_start = int((current_time - start_time) / 60)\n",
    "    minutes_since_last = int((current_time - last_message_time) / 60)\n",
    "    \n",
    "    return MessageContext(\n",
    "        message_number=message_number,\n",
    "        time_of_day=time_of_day,\n",
    "        minutes_since_start=minutes_since_start,\n",
    "        minutes_since_last=minutes_since_last\n",
    "    )\n",
    "\n",
    "def format_chat_history(history):\n",
    "    \"\"\"Convert ChatHistory to formatted string\"\"\"\n",
    "    result = []\n",
    "    for msg in history.messages:\n",
    "        speaker = \"Creator\" if msg.from_creator else \"Fan\"\n",
    "        context = f\"[Time: {msg.context.time_of_day}, Message #{msg.context.message_number}]\"\n",
    "        result.append(f\"{speaker} {context}: {msg.content}\")\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "def format_context(context):\n",
    "    \"\"\"Convert MessageContext to formatted string\"\"\"\n",
    "    return (f\"Current context: Time of day: {context.time_of_day}, \"\n",
    "            f\"Message #{context.message_number}, \"\n",
    "            f\"Minutes since start: {context.minutes_since_start}, \"\n",
    "            f\"Minutes since last: {context.minutes_since_last}\")\n",
    "\n",
    "print(\"Chat started! (Type 'quit' to exit)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "message_counter = 0\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You: \").strip()\n",
    "    \n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"\\nChat ended. Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Update counter and get context\n",
    "    message_counter += 1\n",
    "    context = get_context(message_counter)\n",
    "    \n",
    "    # Append user input to chat history\n",
    "    chat_history.messages.append(\n",
    "        ChatMessage(\n",
    "            from_creator=False,\n",
    "            content=user_input,\n",
    "            context=context\n",
    "        )\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Format inputs as strings\n",
    "        chat_str = format_chat_history(chat_history)\n",
    "        context_str = format_context(context)\n",
    "        \n",
    "        # Get response using loaded model with context\n",
    "        response = chatter(\n",
    "            chat_history=chat_str,\n",
    "            context=context_str\n",
    "        )\n",
    "\n",
    "        # Update last message time\n",
    "        last_message_time = time.time()\n",
    "        \n",
    "        # Update counter and get new context for response\n",
    "        message_counter += 1\n",
    "        context = get_context(message_counter)\n",
    "        \n",
    "        # Append response to chat history\n",
    "        chat_history.messages.append(\n",
    "            ChatMessage(\n",
    "                from_creator=True,\n",
    "                content=response,\n",
    "                context=context\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Print response with some formatting\n",
    "        print(\"\\nCreator:\", response)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        print(\"Please try again.\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f9f99-5f16-480f-aeb7-87f3074b7e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (whisper2)",
   "language": "python",
   "name": "whisper2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

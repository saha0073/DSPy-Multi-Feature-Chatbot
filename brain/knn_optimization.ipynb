{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4b10af-b98f-4c52-b87f-3455ef9f1c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subho\\anaconda3\\envs\\whisper2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models import ChatMessage, ChatHistory\n",
    "import dspy\n",
    "from lms.together import Together\n",
    "\n",
    "from modules.chatter import ChatterModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4dff04-07dd-43eb-825d-c536071f251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = Together(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=1000,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.2,\n",
    "    stop=[\"<|eot_id|>\", \"<|eom_id|>\", \"\\n\\n---\\n\\n\", \"\\n\\n---\", \"---\", \"\\n---\"],\n",
    "    # stop=[\"\\n\", \"\\n\\n\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a389b21-dc30-40fc-80da-f3d743ae2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0d9407-0469-40b8-8e5d-13f451cbeda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 8\n",
      "Dev examples: 2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from models import ChatMessage, ChatHistory\n",
    "\n",
    "# Load the dataset\n",
    "with open('../training_data/conversations.json', 'r') as f:\n",
    "    conversations = json.load(f)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "random.shuffle(conversations)\n",
    "\n",
    "# Split into train (80%) and dev (20%) sets\n",
    "split_idx = int(len(conversations) * 0.8)\n",
    "train_data = conversations[:split_idx]\n",
    "dev_data = conversations[split_idx:]\n",
    "\n",
    "# Create trainset and devset with proper ChatHistory objects\n",
    "def create_example(conv):\n",
    "    # Create ChatHistory object with proper message format\n",
    "    chat_history = ChatHistory(\n",
    "        messages=[\n",
    "            ChatMessage(**msg) for msg in conv['chat_history']['messages']\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return dspy.Example({\n",
    "        'chat_history': chat_history,\n",
    "        'output': conv['output']\n",
    "    }).with_inputs('chat_history')\n",
    "\n",
    "trainset = [create_example(conv) for conv in train_data]\n",
    "devset = [create_example(conv) for conv in dev_data]\n",
    "\n",
    "print(f\"Training examples: {len(trainset)}\")\n",
    "print(f\"Dev examples: {len(devset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d87829e-e5b4-4b65-a246-6d0d2bb8f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example Structure:\n",
      "THE FAN: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "YOU: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "THE FAN: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "[ChatMessage(from_creator=False, content='I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?'), ChatMessage(from_creator=True, content='Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.'), ChatMessage(from_creator=False, content='It feels chaotic, but I also feel like Iâ€™m learning so much about myself.')]\n"
     ]
    }
   ],
   "source": [
    "# Example from trainset\n",
    "example = trainset[0]\n",
    "print(\"Training Example Structure:\")\n",
    "print(example.chat_history)  # This is a ChatHistory object\n",
    "print(example.chat_history.messages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57fd32f8-7528-48cb-a1fe-8e9905179abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import KNNFewShot\n",
    "from modules.chatter import ChatterModule\n",
    "\n",
    "# Create the KNN teleprompter\n",
    "knn_teleprompter = KNNFewShot(7, trainset)\n",
    "\n",
    "# Create an instance of ChatterModule\n",
    "chatter = ChatterModule(examples=None)\n",
    "\n",
    "# Compile with our ChatterModule\n",
    "compiled_knn = knn_teleprompter.compile(chatter, trainset=trainset)\n",
    "\n",
    "# Save the compiled model\n",
    "#compiled_knn.save(\"saved_models/optimized_chatbot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69fff5a8-f06c-4448-84fb-cc7536dbfcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "responder.prog.predictor = Predict(StringSignature(chat_history -> reasoning, output\n",
       "    instructions='You are an OnlyFans creator chatting on OnlyFans with a fan.\\nYou are deciding on what your message should be.'\n",
       "    chat_history = Field(annotation=ChatHistory required=True json_schema_extra={'desc': 'the chat history', '__dspy_field_type': 'input', 'prefix': 'Chat History:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step to decide on our message. We\", '__dspy_field_type': 'output', 'desc': '${reasoning}'})\n",
       "    output = Field(annotation=str required=True json_schema_extra={'prefix': 'Your Message:', 'desc': 'the exact text of the message you will send to the fan.', '__dspy_field_type': 'output'})\n",
       "))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2761968c-c491-48d2-978f-c0b3a92e05ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "responder.prog.predictor = Predict(StringSignature(chat_history -> reasoning, output\n",
       "    instructions='You are an OnlyFans creator chatting on OnlyFans with a fan.\\nYou are deciding on what your message should be.'\n",
       "    chat_history = Field(annotation=ChatHistory required=True json_schema_extra={'desc': 'the chat history', '__dspy_field_type': 'input', 'prefix': 'Chat History:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step to decide on our message. We\", '__dspy_field_type': 'output', 'desc': '${reasoning}'})\n",
       "    output = Field(annotation=str required=True json_schema_extra={'prefix': 'Your Message:', 'desc': 'the exact text of the message you will send to the fan.', '__dspy_field_type': 'output'})\n",
       "))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1085ea-3541-4ded-a5c8-ac51ee0e3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with k=2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\t*** Since DSPy 2.5.16+, TypedPredictors are now deprecated, underperform, and are about to be removed! ***\n",
      "Please use standard predictors, e.g. dspy.Predict and dspy.ChainOfThought.\n",
      "They now support type annotations and other features of TypedPredictors and tend to work much better out of the box.\n",
      "Please let us know if you face any issues: https://github.com/stanfordnlp/dspy/issues\n",
      "  0%|                                                                                        | 0/2 [00:00<?, ?it/s]WARNING:root:\t*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, underperform, and are about to be deleted. ***\n",
      " \t\tYou are using the client Together, which will be removed in DSPy 2.6.\n",
      " \t\tChanging the client is straightforward and will let you use new features (Adapters) that improve the consistency of LM outputs, especially when using chat LMs. \n",
      "\n",
      " \t\tLearn more about the changes and how to migrate at\n",
      " \t\thttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Input conversation:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "\n",
      "Model output: You're navigating through life with courage, allowing yourself to learn and grow from each experience. The uncertainty might seem daunting at times, but remember, clarity often emerges in hindsight. Keep moving forward; every discovery brings you closer to understanding yourself better.\n",
      "\n",
      "Nearest 2 neighbors used:\n",
      "\n",
      "Neighbor 1:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "Response: Thatâ€™s the beauty of self-discovery. Embrace the chaosâ€”it means youâ€™re alive and curious.\n",
      "\n",
      "Neighbor 2:\n",
      "Fan: Do you ever feel like the idea of â€˜self-improvementâ€™ is just another way to make people feel inadequate?\n",
      "Creator: Thatâ€™s a deep question. True self-improvement shouldnâ€™t make you feel lacking. Itâ€™s about becoming more yourself, not something else.\n",
      "Fan: I like that. Like, I can just be me but maybe a little less chaotic?\n",
      "Response: Exactly! Improvement isnâ€™t about fixing, just embracing yourself with more awareness and acceptance.\n",
      "\n",
      "Testing with k=3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 2 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "\n",
      "Input conversation:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "\n",
      "Model output: The journey might seem messy right now, but every new insight brings clarity. Keep exploring; each rediscovery shapes who you'll become next.\n",
      "\n",
      "Nearest 3 neighbors used:\n",
      "\n",
      "Neighbor 1:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "Response: Thatâ€™s the beauty of self-discovery. Embrace the chaosâ€”it means youâ€™re alive and curious.\n",
      "\n",
      "Neighbor 2:\n",
      "Fan: Do you ever feel like the idea of â€˜self-improvementâ€™ is just another way to make people feel inadequate?\n",
      "Creator: Thatâ€™s a deep question. True self-improvement shouldnâ€™t make you feel lacking. Itâ€™s about becoming more yourself, not something else.\n",
      "Fan: I like that. Like, I can just be me but maybe a little less chaotic?\n",
      "Response: Exactly! Improvement isnâ€™t about fixing, just embracing yourself with more awareness and acceptance.\n",
      "\n",
      "Neighbor 3:\n",
      "Fan: I sometimes feel like Iâ€™m an â€˜old soulâ€™ in a world thatâ€™s moving too fast. Is that weird?\n",
      "Creator: Not at all. Some people connect deeply with past eras, and thatâ€™s perfectly valid. Itâ€™s about finding your own rhythm.\n",
      "Fan: Thatâ€™s really reassuring. Sometimes I just want to escape into another time.\n",
      "Response: Thatâ€™s understandable. Just remember that you can bring elements of those eras into your life now.\n",
      "\n",
      "Testing with k=4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "\n",
      "Input conversation:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "\n",
      "Model output: Try journaling these discoveries. Reflecting back might help solidify these new insights about yourself.\n",
      "\n",
      "Nearest 4 neighbors used:\n",
      "\n",
      "Neighbor 1:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "Response: Thatâ€™s the beauty of self-discovery. Embrace the chaosâ€”it means youâ€™re alive and curious.\n",
      "\n",
      "Neighbor 2:\n",
      "Fan: Do you ever feel like the idea of â€˜self-improvementâ€™ is just another way to make people feel inadequate?\n",
      "Creator: Thatâ€™s a deep question. True self-improvement shouldnâ€™t make you feel lacking. Itâ€™s about becoming more yourself, not something else.\n",
      "Fan: I like that. Like, I can just be me but maybe a little less chaotic?\n",
      "Response: Exactly! Improvement isnâ€™t about fixing, just embracing yourself with more awareness and acceptance.\n",
      "\n",
      "Neighbor 3:\n",
      "Fan: I sometimes feel like Iâ€™m an â€˜old soulâ€™ in a world thatâ€™s moving too fast. Is that weird?\n",
      "Creator: Not at all. Some people connect deeply with past eras, and thatâ€™s perfectly valid. Itâ€™s about finding your own rhythm.\n",
      "Fan: Thatâ€™s really reassuring. Sometimes I just want to escape into another time.\n",
      "Response: Thatâ€™s understandable. Just remember that you can bring elements of those eras into your life now.\n",
      "\n",
      "Neighbor 4:\n",
      "Fan: How would you balance being an introvert with the need for connection? I feel like I live in a world of my own...\n",
      "Creator: The key is finding people who appreciate your world rather than requiring you to leave it. True connection can be simple and quiet.\n",
      "Fan: Thatâ€™s really comforting. I always thought connection had to be extroverted.\n",
      "Response: Not at all. Itâ€™s about quality, not quantity. Authentic connection doesnâ€™t demand you to be someone youâ€™re not.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import KNNFewShot\n",
    "from modules.chatter import ChatterModule\n",
    "\n",
    "def metric(example, prediction, trace=None):\n",
    "    return example.output == prediction.output\n",
    "\n",
    "def test_knn(k_value):\n",
    "    print(f\"\\nTesting with k={k_value}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    bootstrap_args = {\n",
    "        'metric': metric,\n",
    "        'max_bootstrapped_demos': 2,\n",
    "        'max_labeled_demos': 4,\n",
    "        'max_rounds': 1,\n",
    "        'max_errors': 5\n",
    "    }\n",
    "\n",
    "    knn_teleprompter = KNNFewShot(\n",
    "        k=k_value,\n",
    "        trainset=trainset,\n",
    "        **bootstrap_args\n",
    "    )\n",
    "\n",
    "    chatter = ChatterModule(examples=None)\n",
    "    compiled_knn = knn_teleprompter.compile(\n",
    "        student=chatter,\n",
    "        trainset=trainset\n",
    "    )\n",
    "\n",
    "    # Test with sample input\n",
    "    test_history = trainset[0].chat_history\n",
    "    result = compiled_knn(chat_history=test_history)\n",
    "    \n",
    "    # Get and print neighbors\n",
    "    neighbors = knn_teleprompter.KNN(chat_history=test_history)\n",
    "    \n",
    "    print(f\"\\nInput conversation:\")\n",
    "    for msg in test_history.messages:\n",
    "        role = \"Fan\" if not msg.from_creator else \"Creator\"\n",
    "        print(f\"{role}: {msg.content}\")\n",
    "    \n",
    "    print(f\"\\nModel output: {result.output}\")\n",
    "    \n",
    "    print(f\"\\nNearest {k_value} neighbors used:\")\n",
    "    for i, n in enumerate(neighbors):\n",
    "        print(f\"\\nNeighbor {i+1}:\")\n",
    "        for msg in n.chat_history.messages:\n",
    "            role = \"Fan\" if not msg.from_creator else \"Creator\"\n",
    "            print(f\"{role}: {msg.content}\")\n",
    "        print(f\"Response: {n.output}\")\n",
    "\n",
    "# Test with different k values\n",
    "for k in [2, 3, 4]:\n",
    "    test_knn(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c37fdf1-d7f7-4bb8-89dc-df99e03a56a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "\n",
      "Test Results:\n",
      "Input conversation:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "\n",
      "Model output: The journey might seem messy now, but every rediscovery brings clarity in its own time. Keep exploring!\n",
      "\n",
      "Nearest neighbors used:\n",
      "\n",
      "Neighbor 1:\n",
      "Fan: I feel like Iâ€™m always â€˜rediscoveringâ€™ myself. Is that normal, or am I just indecisive?\n",
      "Creator: Rediscovery is a sign of growth. Weâ€™re constantly evolving, and itâ€™s healthy to question who you are.\n",
      "Fan: It feels chaotic, but I also feel like Iâ€™m learning so much about myself.\n",
      "Response: Thatâ€™s the beauty of self-discovery. Embrace the chaosâ€”it means youâ€™re alive and curious.\n",
      "\n",
      "Neighbor 2:\n",
      "Fan: Do you ever feel like the idea of â€˜self-improvementâ€™ is just another way to make people feel inadequate?\n",
      "Creator: Thatâ€™s a deep question. True self-improvement shouldnâ€™t make you feel lacking. Itâ€™s about becoming more yourself, not something else.\n",
      "Fan: I like that. Like, I can just be me but maybe a little less chaotic?\n",
      "Response: Exactly! Improvement isnâ€™t about fixing, just embracing yourself with more awareness and acceptance.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import KNNFewShot\n",
    "from modules.chatter import ChatterModule\n",
    "\n",
    "def metric(example, prediction, trace=None):\n",
    "    return example.output == prediction.output\n",
    "\n",
    "# Create the KNN teleprompter with optimal parameters\n",
    "bootstrap_args = {\n",
    "    'metric': metric,\n",
    "    'max_bootstrapped_demos': 2,\n",
    "    'max_labeled_demos': 4,\n",
    "    'max_rounds': 1,\n",
    "    'max_errors': 5\n",
    "}\n",
    "\n",
    "# Initialize KNN with k=2\n",
    "knn_teleprompter = KNNFewShot(\n",
    "    k=2,  # Using 2 nearest neighbors\n",
    "    trainset=trainset,\n",
    "    **bootstrap_args\n",
    ")\n",
    "\n",
    "# Create and compile\n",
    "chatter = ChatterModule(examples=None)\n",
    "compiled_knn = knn_teleprompter.compile(\n",
    "    student=chatter,\n",
    "    trainset=trainset\n",
    ")\n",
    "\n",
    "# Optional: Save the compiled model\n",
    "compiled_knn.save(\"saved_models/optimized_chatbot.json\")\n",
    "\n",
    "# Test the model (optional)\n",
    "def test_model():\n",
    "    test_history = trainset[0].chat_history\n",
    "    result = compiled_knn(chat_history=test_history)\n",
    "    \n",
    "    print(\"\\nTest Results:\")\n",
    "    print(\"Input conversation:\")\n",
    "    for msg in test_history.messages:\n",
    "        role = \"Fan\" if not msg.from_creator else \"Creator\"\n",
    "        print(f\"{role}: {msg.content}\")\n",
    "    \n",
    "    print(f\"\\nModel output: {result.output}\")\n",
    "    \n",
    "    neighbors = knn_teleprompter.KNN(chat_history=test_history)\n",
    "    print(f\"\\nNearest neighbors used:\")\n",
    "    for i, n in enumerate(neighbors):\n",
    "        print(f\"\\nNeighbor {i+1}:\")\n",
    "        for msg in n.chat_history.messages:\n",
    "            role = \"Fan\" if not msg.from_creator else \"Creator\"\n",
    "            print(f\"{role}: {msg.content}\")\n",
    "        print(f\"Response: {n.output}\")\n",
    "\n",
    "# Uncomment to test\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb445463-a5c9-442f-8781-7a37e6c25075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "responder.prog.predictor = Predict(StringSignature(chat_history -> reasoning, output\n",
       "    instructions='You are an OnlyFans creator chatting on OnlyFans with a fan.\\nYou are deciding on what your message should be.'\n",
       "    chat_history = Field(annotation=ChatHistory required=True json_schema_extra={'desc': 'the chat history', '__dspy_field_type': 'input', 'prefix': 'Chat History:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step to decide on our message. We\", '__dspy_field_type': 'output', 'desc': '${reasoning}'})\n",
       "    output = Field(annotation=str required=True json_schema_extra={'prefix': 'Your Message:', 'desc': 'the exact text of the message you will send to the fan.', '__dspy_field_type': 'output'})\n",
       "))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1dadd1-42b7-4103-90e5-beda1344a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: I'm [stage name], nice to meet you! I create exclusive content for my fans here on OF\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  where do you live?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Haha, all over! How about you? What brings you to this corner of the internet?\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m chat_history \u001b[38;5;241m=\u001b[39m ChatHistory()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Get user input\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Append user input to chat history\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     chat_history\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     12\u001b[0m         ChatMessage(\n\u001b[0;32m     13\u001b[0m             from_creator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m             content\u001b[38;5;241m=\u001b[39muser_input,\n\u001b[0;32m     15\u001b[0m         ),\n\u001b[0;32m     16\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\whisper2\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\whisper2\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chatter = ChatterModule(examples=None)  # Create a new instance\n",
    "chatter.load(path=\"saved_models/optimized_chatbot.json\")  # Load the optimized version\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Append user input to chat history\n",
    "    chat_history.messages.append(\n",
    "        ChatMessage(\n",
    "            from_creator=False,\n",
    "            content=user_input,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Send request to endpoint using loaded model\n",
    "    response = chatter(chat_history=chat_history).output\n",
    "\n",
    "    # Append response to chat history\n",
    "    chat_history.messages.append(\n",
    "        ChatMessage(\n",
    "            from_creator=True,\n",
    "            content=response,\n",
    "        ),\n",
    "    )\n",
    "    # Print response\n",
    "    print()\n",
    "    print(\"Response:\", response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb2397-6dbe-4dd7-bbeb-03ccd118b4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (whisper2)",
   "language": "python",
   "name": "whisper2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
